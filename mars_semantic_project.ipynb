{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET PREPARATION\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "h1GeONvLjh1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2 # os - files, oper. sys., cv2 - image processing\n",
        "import numpy as np # arrays\n",
        "import pandas as pd # excel\n",
        "\n",
        "\"\"\"\n",
        "# links on folders with dataset\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "data_folder = 'https://drive.google.com/drive/folders/1BIzPHVNSIMxCZi_lD4kqXwi0QAVrnYNy?usp=sharing' # link of dataset folder\n",
        "\n",
        "img_train_folder = os.path.join(data_folder, 'train')\n",
        "mask_train_folder = os.path.join(data_folder, 'train_labels')\n",
        "\n",
        "img_valid_folder = os.path.join(data_folder, 'valid')\n",
        "mask_valid_folder = os.path.join(data_folder, 'valid_labels')\n",
        "\n",
        "img_test_folder = os.path.join(data_folder, 'test')\n",
        "mask_test_folder = os.path.join(data_folder, 'test_labels')"
      ],
      "metadata": {
        "id": "4NvlOH-4Hzh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# get name of classes and their values\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class_dataframe = pd.read_csv('https://docs.google.com/spreadsheets/d/1yMCRB7ckbci1lfNnwa9XPnflYxrNs8Y2/export?format=csv') # pandas dataframe\n",
        "\n",
        "class_names = class_dataframe['name'].tolist()\n",
        "\n",
        "class_gray_values = class_dataframe['gray'].values.tolist()\n",
        "\n",
        "\n",
        "print('Class Names: ', class_names)\n",
        "print('Class gray values: ', class_gray_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ8_Ep-QZxn_",
        "outputId": "5a1a9bfc-9b77-42a4-9f03-144202d88507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Names:  ['soil', 'bedrock', 'sand', 'big rock', 'rest']\n",
            "Class gray values:  [0, 1, 2, 3, 255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# implementation of the Dataset class\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class CreatImageDataset(Dataset):\n",
        "\n",
        "  def __init__(self, img_folder, mask_folder, transforms)\n",
        "    self.img_folder = img_folder\n",
        "    self.mask_folder = mask_folder\n",
        "    self.transforms = transforms\n",
        "\n",
        "    img_paths = os.listdir(self.img_folder)\n",
        "    img_paths.sort()\n",
        "\n",
        "    mask_paths = os.listdir(self.mask_folder)\n",
        "    mask_paths.sort()\n",
        "\n",
        "\n",
        "    # return the amount of files\n",
        "    def __len__(self):\n",
        "        return len(self.imgs_paths)\n",
        "\n",
        "    # form tensors of the input images and masks\n",
        "    def __getitem__(self, idx):\n",
        "        img = read_image(os.path.join(self.img_folder, self.img_paths[idx]), ImageReadMode.RGB) # get tensor with shape (3,H,W)\n",
        "        mask = read_image(os.path.join(self.mask_folder, self.mask_paths[idx]), ImageReadMode.GRAY) # get tensor with shape (1,H,W)\n",
        "\n",
        "    # apply an augmentation\n",
        "    augmented = self.transforms(image=img, mask=mask)\n",
        "    img = augmented['image']\n",
        "    mask = augmented['mask']\n"
      ],
      "metadata": {
        "id": "anf6Fp_OvxyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUGMENTATION"
      ],
      "metadata": {
        "id": "N7CpZO5yUUPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# augmentation functions\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import albumentations as aug\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "def get_train_transforms(image_size=(512, 512)):\n",
        "    h, w = image_size\n",
        "    return aug.Compose([    # albumentations transformation pipeline builder\n",
        "\n",
        "    ],)\n",
        "\n",
        "\n",
        "def get_valid_transforms(image_size=(512, 512)):\n",
        "    h, w = image_size\n",
        "    return aug.Compose([\n",
        "\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "ChgjvdXgDT55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oRp-ThHxVt5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3GnymIQ8Vx3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qJzi2gCNV4Pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEPLOYMENT\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ARYRIsfnV-Xi"
      }
    }
  ]
}